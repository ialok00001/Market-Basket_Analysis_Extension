{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a97212",
   "metadata": {},
   "source": [
    "# Market-Basket Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004b5de",
   "metadata": {},
   "source": [
    "From a given set of items I and a set of transactions T, count the number of maps X $\\to$ Y such that\n",
    "   $X,Y \\in I$, $X\\cap Y$=$\\phi$,\n",
    "-   If X is bought, then it is very likely that Y is also bought.\n",
    "-   i.e., if $X\\subseteq t_j$, then it is very likely that $Y\\subseteq t_j$.\n",
    "\n",
    "Supermarkets use this analysis very frequently. By finding such patterns, they can keep these frequently bought items next to each other in the shop.\n",
    "This will increase their productivity as customers will be even more eager to buy both the items simultaneously.\n",
    "\n",
    "As an example, there is the diaper-beer legend. Wal-mart once made such an analysis on the items which were bought in their stores by customers. They found out that, usually on Fridays the dads who bought diapers also tend to buy beers. This was a very unexpected finding. At first there seems to be no connection between diapers and beer.\n",
    "It was later concluded that the men who bought diapers on Fridays, to give themselves a reward to work on weekdays and since their was no time left to go to the beer shop, they bought the beers and took them home.\n",
    "\n",
    "Though this technique was initially developed for shop owners, it can also be applied in other cases too where we want to find patterns of set of events that occured together frequently. For example, from the list of weak concepts for each student, we can tell that a student having difficulty in understanding concept A also tend to have difficulty in understanding concept B.\n",
    "\n",
    "This technique is difficult to implement when one needs to make complex machine learning programs such as Decision Trees, Bayesian Classifiers or Deep Learning Models. But on the positive side, this technique has a plus point of providing a high level explainability that other complex models lack. As we will see, we can even make a classification model with certain datasets with this technique, though not in the way we are used to, but giving us the associations between attributes and their corresponding target class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d72a0c3",
   "metadata": {},
   "source": [
    "## Support and confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27056437",
   "metadata": {},
   "source": [
    "Confidence level $\\chi$\n",
    "\n",
    "-   How frequently does X $\\subseteq$ $t_j$ imply Y $\\subseteq$ $t_j$\n",
    "$$\\frac{(X\\cup Y).count}{X.count}\\geq \\chi$$\n",
    "\n",
    "Support level $\\sigma$\n",
    "\n",
    "-   How significant is this pattern\n",
    "$$\\frac{(X\\cup Y).count}{M}\\geq\\sigma$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96be642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the support and confidence level.\n",
    "# We can change them as our requirements.\n",
    "\n",
    "support = 0.01\n",
    "confidence = 0.40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d66a2e",
   "metadata": {},
   "source": [
    "### Uploading a dataset to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83495d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a4b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\groceries - groceries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b337db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item(s)</th>\n",
       "      <th>Item 1</th>\n",
       "      <th>Item 2</th>\n",
       "      <th>Item 3</th>\n",
       "      <th>Item 4</th>\n",
       "      <th>Item 5</th>\n",
       "      <th>Item 6</th>\n",
       "      <th>Item 7</th>\n",
       "      <th>Item 8</th>\n",
       "      <th>Item 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Item 23</th>\n",
       "      <th>Item 24</th>\n",
       "      <th>Item 25</th>\n",
       "      <th>Item 26</th>\n",
       "      <th>Item 27</th>\n",
       "      <th>Item 28</th>\n",
       "      <th>Item 29</th>\n",
       "      <th>Item 30</th>\n",
       "      <th>Item 31</th>\n",
       "      <th>Item 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>citrus fruit</td>\n",
       "      <td>semi-finished bread</td>\n",
       "      <td>margarine</td>\n",
       "      <td>ready soups</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>tropical fruit</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>coffee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>whole milk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>pip fruit</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>cream cheese</td>\n",
       "      <td>meat spreads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>other vegetables</td>\n",
       "      <td>whole milk</td>\n",
       "      <td>condensed milk</td>\n",
       "      <td>long life bakery product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item(s)            Item 1               Item 2          Item 3  \\\n",
       "0        4      citrus fruit  semi-finished bread       margarine   \n",
       "1        3    tropical fruit               yogurt          coffee   \n",
       "2        1        whole milk                  NaN             NaN   \n",
       "3        4         pip fruit               yogurt    cream cheese   \n",
       "4        4  other vegetables           whole milk  condensed milk   \n",
       "\n",
       "                     Item 4 Item 5 Item 6 Item 7 Item 8 Item 9  ... Item 23  \\\n",
       "0               ready soups    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
       "1                       NaN    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
       "2                       NaN    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
       "3              meat spreads    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
       "4  long life bakery product    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
       "\n",
       "  Item 24 Item 25 Item 26 Item 27 Item 28 Item 29 Item 30 Item 31 Item 32  \n",
       "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef9606",
   "metadata": {},
   "source": [
    "**Note:** We can download the above dataset from Kaggle using this link - https://www.kaggle.com/datasets/irfanasrullah/groceries?select=groceries.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717cc4b",
   "metadata": {},
   "source": [
    "First we need some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60aa75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=[\"Item(s)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153377f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M, _ = dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf967ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9835"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9bba0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of all the transactions\n",
    "\n",
    "T = {}\n",
    "\n",
    "for i in range(M):\n",
    "    T[i] = list(dataset.iloc[i,:].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb231d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['citrus fruit', 'semi-finished bread', 'margarine', 'ready soups']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c99640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating a list of all the available items\n",
    "\n",
    "I = set()\n",
    "\n",
    "for i in range(M):\n",
    "    I = I.union(set(list(dataset.iloc[i,:].dropna())))\n",
    "I = list(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a67f2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbf6ab",
   "metadata": {},
   "source": [
    "Now that our list of all items and the transactions are made, we are ready to begin with our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba29c6",
   "metadata": {},
   "source": [
    "## Finding the frequent itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5f016e",
   "metadata": {},
   "source": [
    "First we have to find the frequent itemsets (sets of items with enough support).\n",
    "\n",
    "i.e., we have to find the items Z$\\subseteq$ I such that $Z.count\\geq \\sigma . M$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453e612",
   "metadata": {},
   "source": [
    "I = $\\{i_1,i_2, \\dots, i_N\\}$\n",
    "\n",
    "T = $\\{t_1,t_2,\\dots, t_M\\}$ where $t_j\\subset I$ for all j\n",
    "\n",
    "To find Z $\\subset$ I such that Z.count $>=$ $\\sigma$ .M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce4a5e",
   "metadata": {},
   "source": [
    "### 1) The Naive Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f84ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code should not be executed due to exponential time complexity.\n",
    "\n",
    "# subsets = [[]] # Returns all subsets of I (The power set of I)\n",
    "# for el in I:\n",
    "#     subsets += [s+[el] for s in subsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02687540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_frequent_itemsets(q):\n",
    "    frequent = []\n",
    "    for Z in subsets:\n",
    "        c=0\n",
    "        for t in T:\n",
    "            if Z in t:\n",
    "                c+=1\n",
    "        if c>=q*M:\n",
    "            frequent.append(Z)\n",
    "    return frequent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b1f5ad",
   "metadata": {},
   "source": [
    "But this causes to produce all the subsets of I ($2^N$ many of them) and then maintain $2^N$ many counters. This is computationally very expensive. Usually we will be having a very large number of items to check through.\n",
    "\n",
    "Is there any better strategy to count the frequent itemsets ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b08f5cf",
   "metadata": {},
   "source": [
    "### 2) The Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64131756",
   "metadata": {},
   "source": [
    "Lets assume a bound on $|t_j|$ for each $t_j\\in M$ (there must be a limit to the number of items a customer buys).\n",
    "Lets say the threshold is 10\n",
    "\n",
    "Say N = |I| = $10^6$ and M = |T| = $10^9$, $\\sigma = 0.01$ ($1 \\%$)\n",
    "\n",
    "So we only have to count $\\sum_{i=1}^{10} \\binom{10^6}{i}$ subsets of I."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c136d",
   "metadata": {},
   "source": [
    "###### The first important strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d117c",
   "metadata": {},
   "source": [
    "If $Z\\subseteq I$ is a frequent itemset, i.e.,\n",
    "$$Z.count \\geq \\sigma . M$$\n",
    "then each element of Z is also a frequent itemset (a singleton set).\n",
    "\n",
    "Hence if we count all the frequent singleton itemsets, we can build on them to find all the frequent itemsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5219b",
   "metadata": {},
   "source": [
    "Since threshold on each transaction is 10 and there are total $10^9$ transactions, there will be at most $10^{10}$ items in $T$.\n",
    "\n",
    "Also, an item $\\{x\\}$ that is frequent will appear in at least $10^9 \\times 0.01 = {10}^7$ transactions.\n",
    "\n",
    "Hence there will be at most $10^{10}/10^7 = 1000$ items that are frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76712c05",
   "metadata": {},
   "source": [
    "#### Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71049784",
   "metadata": {},
   "source": [
    "If Z is a frequent itemset, then each $Y\\subseteq Z$ will also be frequent.\n",
    "\n",
    "Also, if Z is not frequent, then no Y such that $Z\\subseteq Y$ can be frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86306acd",
   "metadata": {},
   "source": [
    "If $\\{x,y\\}$ are frequent, then so are $\\{x\\}$ and $\\{y\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcfafa0",
   "metadata": {},
   "source": [
    "We can build on this inductively starting from singleton frequent itemsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc27064",
   "metadata": {},
   "source": [
    "$F_1$ = collection of frequent itemsets $\\{x\\}$ in I\n",
    "\n",
    "$C_2$ = all tuples from elements of $F_1$\n",
    "\n",
    "$F_2$ = all the frequent itemsets from $C_2$\n",
    "\n",
    "$C_3$ = $\\{\\{x,y,z\\} \\text{ }|\\text{ } \\{x,y\\}, \\text{ }\\{y,z\\},\\text{ }\\{x,z\\}\\text{ }\\in F_2 \\}$\n",
    "\n",
    "$F_3$ = $\\{l\\in C_3\\text{ }| \\text{ } l\\text{.count} \\geq \\sigma.M\\}$\n",
    "\n",
    "$C_k$ = subsets of size k, such that each of their (k-1) subsets are in $F_{k-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c86f6f",
   "metadata": {},
   "source": [
    "And so on, we can work for all such frequent itemsets.\n",
    "\n",
    "When to Stop ?\n",
    "     When there are no items to check or when we have reached the threshold (like 10 in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d1d39",
   "metadata": {},
   "source": [
    "But even generating C_k is also expensive, since it has to check for al the k-1 subsets in $F_{k-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3fff2",
   "metadata": {},
   "source": [
    "If $C_k$ $\\subseteq$ $C_k^{'}$, then this $C_k^{'}$ will also work to find $F_{k+1}$\n",
    "\n",
    "\n",
    "\n",
    "What we will do is first decide a numerical indexing for all the items. Any indexing will do.\n",
    "\n",
    "Now we will be able to arrange the items $$i_1<i_2<\\dots<i_N$$\n",
    "\n",
    "From $F_k$, list the elements in ascending order.\n",
    "\n",
    "Merge two k subsets from this $F_{k}$ if their first first k-1 elements are same and they only differ in their last element.\n",
    "\n",
    "X = $\\{i_1, i_2, \\dots, i_{k-1}, i_k\\}$\n",
    "\n",
    "$X^{'}$ = $\\{i_1,i_2, \\dots, i_{k-1}, i_k^{'}\\}$\n",
    "\n",
    "Assuming $i_k < i_k^{'}$\n",
    "\n",
    "Merge($X,X^{'}$) = $\\{i_1,i_2,\\dots, i_{k-1}, i_k, i_k^{'}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e2ad39",
   "metadata": {},
   "source": [
    "$C_{k+1}^{'} $ = $\\{Merge(X,X^{'})\\text{ }| \\text{ } X,X^{'}\\in F_k\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae274f73",
   "metadata": {},
   "source": [
    "Now we claim that $C_k\\subseteq C_k^{'}$\n",
    "\n",
    "Suppose that $w = \\{i_1,i_2,\\dots, i_{k-1}, i_k\\}\\in C_k$\n",
    "\n",
    "Then $w_1 = \\{i_1,i_2,\\dots, i_{k-1}\\}\\in F_{k-1}$\n",
    "\n",
    "Also, $w_2 = \\{i_1,i_2,\\dots, i_{k-2}, i_k\\}\\in F_{k-1}$\n",
    "$\\Rightarrow Merge(w_1,w_2) = w\\in C_k^{'}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaec8c",
   "metadata": {},
   "source": [
    "Note that |$C_k^{'}$| $\\geq $ |$C_k$| so finding $F_{k+1}$ from $C_k^{'}$ will take more steps. But also we are able to generate $C_k^{'}$ very efficiently than generating $C_k$. This compensates the earlier complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5ccc9",
   "metadata": {},
   "source": [
    "Let us find the largets size of a transaction in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cef9c92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the size of largest transaction\n",
    "m = 0\n",
    "for i in T.keys():\n",
    "    a = len(T[i])\n",
    "    if a > m:\n",
    "        m = a\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d9da7",
   "metadata": {},
   "source": [
    "Before we move on with our project, we will first assign each item a unique number. Then we make two dictionaries to convert between names and unique numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe24259",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_num = dict(zip(I, range(N)))\n",
    "num_to_name = dict(zip(range(N), I))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffd1beb",
   "metadata": {},
   "source": [
    "This is done so that our program uses digits to compute and not strings of characters. Working with integers is easier than working with strings because they are less expensive in both memory and complexity. By the two dictionaries above, we can change back and forth between both notations whenever we feel like.\n",
    "\n",
    "Ideally, we will do all our computations with numbers and then change them back to their corresponding names only at the time of output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ca36bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_num = dict()\n",
    "for key in T.keys():\n",
    "    T_num[key] = [name_to_num[x] for x in T[key]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8b886",
   "metadata": {},
   "source": [
    "We will make a count function to count the number of transactions a particular itemset is a subset of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cd1b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(Z):\n",
    "    c = 0\n",
    "    for i in range(M):\n",
    "        if set(Z).issubset(set(T_num[i])):\n",
    "            c += 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e18326b",
   "metadata": {},
   "source": [
    "Now let's code what we discussed everything above and find the frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d00ef62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent = {}\n",
    "C = {}\n",
    "\n",
    "# Frequent itemsets of size 1\n",
    "C[1] = [[t] for t in list(range(N))]\n",
    "frequent[1] = [t for t in C[1] if count(t) >= M*support]\n",
    "\n",
    "\n",
    "# Frequent itemsets of size >= 2\n",
    "k = 2\n",
    "while(k <= m and len(frequent[k-1]) >= 2):\n",
    "    C[k] = []\n",
    "    x = frequent[k-1]\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        for j in range(i+1, len(x)):\n",
    "            if k == 1:\n",
    "                if x[i] < x[j]:\n",
    "                    C[2].append([x[i], x[j]])\n",
    "                else:\n",
    "                    C[2].append([x[j], x[i]])\n",
    "            else:\n",
    "                if x[i][:-1] == x[j][:-1]:\n",
    "                    if x[i][-1] < x[j][-1]:\n",
    "                        C[k].append(x[i][:-1] + [x[i][-1]] + [x[j][-1]])\n",
    "                    else:\n",
    "                        C[k].append(x[i][:-1] + [x[j][-1]] + [x[i][-1]])\n",
    "    frequent[k] = [t for t in C[k] if count(t) >= M*support]\n",
    "    k += 1\n",
    "\n",
    "del frequent[k-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b426eafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527aa67c",
   "metadata": {},
   "source": [
    "This finishes our apriori algorithm.\n",
    "\n",
    "Now we go to the more challenging part - the association rule mining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95bde6b",
   "metadata": {},
   "source": [
    "### Association rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46fc9ac",
   "metadata": {},
   "source": [
    "We have to find such $X\\cup Y$ frequent itemsets such that $X\\to Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e1bff4",
   "metadata": {},
   "source": [
    "i.e., $$\\frac{(X\\cup Y).count}{X.count}\\geq \\chi$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f5be7e",
   "metadata": {},
   "source": [
    "First lets go with the easy and most widely used case - the one to one case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f6ef0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = frequent[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab112ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) butter -> whole milk, with support = 2.76% and confidence = 49.72%\n",
      "2) yogurt -> whole milk, with support = 5.60% and confidence = 40.16%\n",
      "3) oil -> whole milk, with support = 1.13% and confidence = 40.22%\n",
      "4) frozen vegetables -> whole milk, with support = 2.04% and confidence = 42.49%\n",
      "5) margarine -> whole milk, with support = 2.42% and confidence = 41.32%\n",
      "6) hard cheese -> whole milk, with support = 1.01% and confidence = 41.08%\n",
      "7) domestic eggs -> whole milk, with support = 3.00% and confidence = 47.28%\n",
      "8) hamburger meat -> whole milk, with support = 1.47% and confidence = 44.34%\n",
      "9) chicken -> whole milk, with support = 1.76% and confidence = 41.00%\n",
      "10) whipped/sour cream -> whole milk, with support = 3.22% and confidence = 44.96%\n",
      "11) white bread -> whole milk, with support = 1.71% and confidence = 40.58%\n",
      "12) curd -> whole milk, with support = 2.61% and confidence = 49.05%\n",
      "13) root vegetables -> whole milk, with support = 4.89% and confidence = 44.87%\n",
      "14) beef -> whole milk, with support = 2.13% and confidence = 40.50%\n",
      "15) sliced cheese -> whole milk, with support = 1.08% and confidence = 43.98%\n",
      "16) cream cheese -> whole milk, with support = 1.65% and confidence = 41.54%\n",
      "17) ham -> whole milk, with support = 1.15% and confidence = 44.14%\n",
      "18) butter milk -> whole milk, with support = 1.16% and confidence = 41.45%\n",
      "19) sugar -> whole milk, with support = 1.50% and confidence = 44.44%\n",
      "20) tropical fruit -> whole milk, with support = 4.23% and confidence = 40.31%\n",
      "21) onions -> other vegetables, with support = 1.42% and confidence = 45.90%\n",
      "22) hamburger meat -> other vegetables, with support = 1.38% and confidence = 41.59%\n",
      "23) chicken -> other vegetables, with support = 1.79% and confidence = 41.71%\n",
      "24) whipped/sour cream -> other vegetables, with support = 2.89% and confidence = 40.28%\n",
      "25) root vegetables -> other vegetables, with support = 4.74% and confidence = 43.47%\n"
     ]
    }
   ],
   "source": [
    "q = 1\n",
    "for f in A:\n",
    "    x,y = f[0],f[1]\n",
    "    if count(f) >= confidence * count([x]):\n",
    "        print(str(q) + ') ' + str(num_to_name[x]) +' -> ' + str(num_to_name[y]) + ', with support = ' + '{:.2f}'.format(count(f)/M * 100) + '% and confidence = ' + '{:.2f}'.format(count(f)/count([x]) * 100) + '%')\n",
    "        q += 1\n",
    "    if count(f) >= confidence * count([y]):\n",
    "        print(str(q) + ') ' + str(num_to_name[y]) +' -> ' + str(num_to_name[x]) + ', with support = ' + '{:.2f}'.format(count(f)/M * 100) + '% and confidence = ' + '{:.2f}'.format(count(f)/count([y]) * 100) + '%')\n",
    "        q += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127d844",
   "metadata": {},
   "source": [
    "The output obtained above gives us a lot of insights about the grocery store and its customers. For instance, from the 6th output above, nearly 50% of customers who bought butter also bought whole milk.\n",
    "\n",
    "There are many other such insights in the above output. We can look at the more specific ones my tweaking the values of support and confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ebd4a",
   "metadata": {},
   "source": [
    "It should be noted that this is a very special case of Machine Learning, where the machine finds patterns in the data and displays them to its users so that they can get new insights from them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dada70b",
   "metadata": {},
   "source": [
    "There is another case where we can apply this method.\n",
    "\n",
    "Suppose we are given a bunch of lists with some common categrical values and corresponding to each list there is a target category in which that list belongs. We want to understand what kinds of words are needed together to classify them into a particular category, i.e., we want to learn the relation between list values and their corresponding categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c5ddfa",
   "metadata": {},
   "source": [
    "In this case, we can tweak the algorithms above and make use of the `many to one` case, having maps from subsets of lists to the categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6602ffe1",
   "metadata": {},
   "source": [
    "This is where the fun part of this algorithm begins. But since this project have already been very long, we will just construct the general `many to one` case for the above dataset and call it a day. We will be doing the other case of this algorithm in a future project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eef8af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = []\n",
    "for i in frequent.keys():\n",
    "    if i >=2:\n",
    "        B = B + frequent[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aed2d5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) ['butter'] -> whole milk, with support = 2.76% and confidence = 49.72%\n",
      "2) ['yogurt'] -> whole milk, with support = 5.60% and confidence = 40.16%\n",
      "3) ['oil'] -> whole milk, with support = 1.13% and confidence = 40.22%\n",
      "4) ['frozen vegetables'] -> whole milk, with support = 2.04% and confidence = 42.49%\n",
      "5) ['margarine'] -> whole milk, with support = 2.42% and confidence = 41.32%\n",
      "6) ['hard cheese'] -> whole milk, with support = 1.01% and confidence = 41.08%\n",
      "7) ['domestic eggs'] -> whole milk, with support = 3.00% and confidence = 47.28%\n",
      "8) ['hamburger meat'] -> whole milk, with support = 1.47% and confidence = 44.34%\n",
      "9) ['chicken'] -> whole milk, with support = 1.76% and confidence = 41.00%\n",
      "10) ['whipped/sour cream'] -> whole milk, with support = 3.22% and confidence = 44.96%\n",
      "11) ['white bread'] -> whole milk, with support = 1.71% and confidence = 40.58%\n",
      "12) ['curd'] -> whole milk, with support = 2.61% and confidence = 49.05%\n",
      "13) ['root vegetables'] -> whole milk, with support = 4.89% and confidence = 44.87%\n",
      "14) ['beef'] -> whole milk, with support = 2.13% and confidence = 40.50%\n",
      "15) ['sliced cheese'] -> whole milk, with support = 1.08% and confidence = 43.98%\n",
      "16) ['cream cheese'] -> whole milk, with support = 1.65% and confidence = 41.54%\n",
      "17) ['ham'] -> whole milk, with support = 1.15% and confidence = 44.14%\n",
      "18) ['butter milk'] -> whole milk, with support = 1.16% and confidence = 41.45%\n",
      "19) ['sugar'] -> whole milk, with support = 1.50% and confidence = 44.44%\n",
      "20) ['tropical fruit'] -> whole milk, with support = 4.23% and confidence = 40.31%\n",
      "21) ['onions'] -> other vegetables, with support = 1.42% and confidence = 45.90%\n",
      "22) ['hamburger meat'] -> other vegetables, with support = 1.38% and confidence = 41.59%\n",
      "23) ['chicken'] -> other vegetables, with support = 1.79% and confidence = 41.71%\n",
      "24) ['whipped/sour cream'] -> other vegetables, with support = 2.89% and confidence = 40.28%\n",
      "25) ['root vegetables'] -> other vegetables, with support = 4.74% and confidence = 43.47%\n",
      "26) ['butter', 'other vegetables'] -> whole milk, with support = 1.15% and confidence = 57.36%\n",
      "27) ['whole milk', 'butter'] -> other vegetables, with support = 1.15% and confidence = 41.70%\n",
      "28) ['yogurt', 'citrus fruit'] -> whole milk, with support = 1.03% and confidence = 47.42%\n",
      "29) ['yogurt', 'other vegetables'] -> whole milk, with support = 2.23% and confidence = 51.29%\n",
      "30) ['yogurt', 'whipped/sour cream'] -> whole milk, with support = 1.09% and confidence = 52.45%\n",
      "31) ['yogurt', 'curd'] -> whole milk, with support = 1.01% and confidence = 58.24%\n",
      "32) ['yogurt', 'root vegetables'] -> whole milk, with support = 1.45% and confidence = 56.30%\n",
      "33) ['yogurt', 'rolls/buns'] -> whole milk, with support = 1.56% and confidence = 45.27%\n",
      "34) ['yogurt', 'tropical fruit'] -> whole milk, with support = 1.51% and confidence = 51.74%\n",
      "35) ['citrus fruit', 'other vegetables'] -> whole milk, with support = 1.30% and confidence = 45.07%\n",
      "36) ['whole milk', 'citrus fruit'] -> other vegetables, with support = 1.30% and confidence = 42.67%\n",
      "37) ['pastry', 'other vegetables'] -> whole milk, with support = 1.06% and confidence = 46.85%\n",
      "38) ['bottled water', 'other vegetables'] -> whole milk, with support = 1.08% and confidence = 43.44%\n",
      "39) ['other vegetables', 'pip fruit'] -> whole milk, with support = 1.35% and confidence = 51.75%\n",
      "40) ['whole milk', 'pip fruit'] -> other vegetables, with support = 1.35% and confidence = 44.93%\n",
      "41) ['other vegetables', 'domestic eggs'] -> whole milk, with support = 1.23% and confidence = 55.25%\n",
      "42) ['whole milk', 'domestic eggs'] -> other vegetables, with support = 1.23% and confidence = 41.02%\n",
      "43) ['other vegetables', 'whipped/sour cream'] -> whole milk, with support = 1.46% and confidence = 50.70%\n",
      "44) ['whole milk', 'whipped/sour cream'] -> other vegetables, with support = 1.46% and confidence = 45.43%\n",
      "45) ['other vegetables', 'fruit/vegetable juice'] -> whole milk, with support = 1.05% and confidence = 49.76%\n",
      "46) ['other vegetables', 'root vegetables'] -> whole milk, with support = 2.32% and confidence = 48.93%\n",
      "47) ['whole milk', 'root vegetables'] -> other vegetables, with support = 2.32% and confidence = 47.40%\n",
      "48) ['other vegetables', 'pork'] -> whole milk, with support = 1.02% and confidence = 46.95%\n",
      "49) ['whole milk', 'pork'] -> other vegetables, with support = 1.02% and confidence = 45.87%\n",
      "50) ['other vegetables', 'rolls/buns'] -> whole milk, with support = 1.79% and confidence = 42.00%\n",
      "51) ['other vegetables', 'soda'] -> whole milk, with support = 1.39% and confidence = 42.55%\n",
      "52) ['other vegetables', 'tropical fruit'] -> whole milk, with support = 1.71% and confidence = 47.59%\n",
      "53) ['whole milk', 'tropical fruit'] -> other vegetables, with support = 1.71% and confidence = 40.38%\n",
      "54) ['root vegetables', 'rolls/buns'] -> whole milk, with support = 1.27% and confidence = 52.30%\n",
      "55) ['root vegetables', 'tropical fruit'] -> whole milk, with support = 1.20% and confidence = 57.00%\n",
      "56) ['rolls/buns', 'tropical fruit'] -> whole milk, with support = 1.10% and confidence = 44.63%\n",
      "57) ['yogurt', 'whipped/sour cream'] -> other vegetables, with support = 1.02% and confidence = 49.02%\n",
      "58) ['yogurt', 'root vegetables'] -> other vegetables, with support = 1.29% and confidence = 50.00%\n",
      "59) ['yogurt', 'tropical fruit'] -> other vegetables, with support = 1.23% and confidence = 42.01%\n",
      "60) ['citrus fruit', 'root vegetables'] -> other vegetables, with support = 1.04% and confidence = 58.62%\n",
      "61) ['root vegetables', 'rolls/buns'] -> other vegetables, with support = 1.22% and confidence = 50.21%\n",
      "62) ['root vegetables', 'tropical fruit'] -> other vegetables, with support = 1.23% and confidence = 58.45%\n"
     ]
    }
   ],
   "source": [
    "q = 1\n",
    "for f in B:\n",
    "    for c in range(len(f)):\n",
    "        r = f[c]\n",
    "        l = f[:c] + f[c+1:]\n",
    "        if count(f) >= confidence * count(l):\n",
    "            left = []\n",
    "            for i in l:\n",
    "                left.append(num_to_name[i])\n",
    "            print(str(q) + ') ' + str(left) +' -> ' + str(num_to_name[r]) + ', with support = ' + '{:.2f}'.format(count(f)/M * 100) + '% and confidence = ' + '{:.2f}'.format(count(f)/count(l) * 100) + '%')\n",
    "            q += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919e289",
   "metadata": {},
   "source": [
    "**Note:** The other case of this algorithm will be covered in a future project, using the `many to one` algorithm above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
